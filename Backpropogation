#Importing Libraries
from math import exp
from random import random, seed

#Initalizing Network Framework
def initialize_network(n_inputs,n_hidden,n_outputs):
    network = list()
    hidden_layer = [{'weights':[random() for i in range (n_inputs+1)]} for i in range(n_hidden)]
    network.append(hidden_layer)
    print("h", hidden_layer)
    output_layer = [{'weights':[random() for i in range (n_inputs+1)]} for i in range(n_hidden)]
    print('o',output_layer)
    network.append(output_layer)
    return network

if __name__ == '__main__':
    n = initialize_network(3,3,1)
    print(n)
    
#Activation Function
def activate(weights, inputs):
    bias = weights[-1]
    for i in range(len(weights)-1):
        activation = bias + (weights[i]*inputs[i])
    return activation
    
def transfer(activation):
    return 1.0/(1.0 + exp(-activation))
    
   
# Forward Pass
def forward_progate(network,x):
    inputs = x
    for layer in network:
        new_input = []
        for neuron in layer:
            activation = activate(neuron['Weights'],inputs)
            neuron['output'] = transfer(activation)
            new_inputs.append(neuron['output'])
        inputs = new_inputs
        return inputs
        
        
#Calculate derevative
def transfer_dravitive(output):
    return output*(1.0 - output)
    
#Defining Error
def backward_propogate_error(network,expected):
    for i in reversed(range(len(network))):
        layer = network[i]
        errors = list()
        if i != len(network)-1:
            for j in range(len(layer)):
                error = 0.0
                
                for neuron in network[i+1]:
                    error += (neuron['weights'][j]*neuron['delta'])
                    errors.append(error)
                    
        else:
            for j in range(len(layer)):
                neuron = layer[j]
                errors.append(expected[j] - neuron['output'])
        for j in range(len(layer)):
            neuron = layer[j]
            neuron['delta'] = errors[j]*transfer_dravitive(neuron['output'])
            
            
#Weight Updation
def update_weights(network,row,l_rate):
    for i in range(len(network)):
        inputs = row[:-1]
        if i != 0:
            inputs = [neuron['output'] for neuron in network[i - 1]]
        for neuron
